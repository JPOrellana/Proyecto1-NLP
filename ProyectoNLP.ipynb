{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bbe6918",
   "metadata": {},
   "source": [
    "### **Proyecto 1 NLP – Clasificación supervisada**\n",
    "#### Curso: Procesamiento de Lenguaje Natural\n",
    "#### Universidad del Valle de Guatemala\n",
    "#### **Autores:** José Pablo Orellana y Diego Alberto Leiva\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12202361",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cdae7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "import nltk\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7582fdd",
   "metadata": {},
   "source": [
    "### Cargar Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae1f861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros totales: 3001\n",
      "   Unnamed: 0                                          review_en  \\\n",
      "0           0  One of the other reviewers has mentioned that ...   \n",
      "1           1  A wonderful little production. The filming tec...   \n",
      "2           2  I thought this was a wonderful way to spend ti...   \n",
      "\n",
      "                                           review_es sentiment sentimiento  \n",
      "0  Uno de los otros críticos ha mencionado que de...  positive    positivo  \n",
      "1  Una pequeña pequeña producción.La técnica de f...  positive    positivo  \n",
      "2  Pensé que esta era una manera maravillosa de p...  positive    positivo  \n"
     ]
    }
   ],
   "source": [
    "# Corpus obtenido en Kaggle: https://www.kaggle.com/datasets/luisdiegofv97/imdb-dataset-of-50k-movie-reviews-spanish\n",
    "\n",
    "path = \"Data/reviews_imdb_es.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(f\"Registros totales: {len(df)}\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5485d5",
   "metadata": {},
   "source": [
    "### Renombrar correctamente las columnas y mapear etiquetas en binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cee6f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas originales: ['review_en', 'review_es', 'sentiment', 'sentimiento']\n",
      "Filas válidas: 3,001\n",
      "                                              reseña  sentimiento\n",
      "0  Uno de los otros críticos ha mencionado que de...            1\n",
      "1  Una pequeña pequeña producción.La técnica de f...            1\n",
      "2  Pensé que esta era una manera maravillosa de p...            1\n"
     ]
    }
   ],
   "source": [
    "# Carga total \n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "    sep=None,\n",
    "    engine=\"python\",\n",
    "    quotechar='\"',\n",
    "    escapechar=\"\\\\\",\n",
    "    encoding=\"utf-8\",\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "\n",
    "# --- Limpieza de columnas ---\n",
    "drop_cols = [c for c in df.columns if str(c).strip().lower().startswith(\"unnamed\") or str(c).strip()==\"\"]\n",
    "if drop_cols:\n",
    "    df = df.drop(columns=drop_cols)\n",
    "\n",
    "# Normalizar los nombres\n",
    "df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "print(\"Columnas originales:\", df.columns.tolist())\n",
    "\n",
    "# Verificamos que existan las columnas necesarias\n",
    "if \"review_es\" not in df.columns:\n",
    "    raise ValueError(\"No se encontró la columna 'review_es' en el archivo CSV.\")\n",
    "if \"sentimiento\" not in df.columns and \"sentiment\" not in df.columns:\n",
    "    raise ValueError(\"No se encontró una columna de sentimiento ('sentimiento' o 'sentiment').\")\n",
    "\n",
    "# Escoger la correcta\n",
    "col_text = \"review_es\"\n",
    "col_label = \"sentimiento\" if \"sentimiento\" in df.columns else \"sentiment\"\n",
    "\n",
    "# Mantener solo esas y renombrar\n",
    "df = df[[col_text, col_label]].rename(columns={col_text: \"reseña\", col_label: \"sentimiento\"})\n",
    "\n",
    "# Mapear etiquetas a 0/1 si son texto\n",
    "mapa = {\n",
    "    \"positivo\": 1, \"positive\": 1, \"pos\": 1, \"1\": 1, 1: 1, True: 1,\n",
    "    \"negativo\": 0, \"negative\": 0, \"neg\": 0, \"0\": 0, 0: 0, False: 0\n",
    "}\n",
    "df[\"sentimiento\"] = df[\"sentimiento\"].astype(str).str.strip().str.lower().map(mapa)\n",
    "\n",
    "# Quitar vacíos o nulos\n",
    "df = df.dropna(subset=[\"reseña\", \"sentimiento\"])\n",
    "df = df[df[\"reseña\"].astype(str).str.strip().str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"Filas válidas: {len(df):,}\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658951e",
   "metadata": {},
   "source": [
    "### Normalización de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "012ae355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo (antes y después):\n",
      "\n",
      "- Original: Uno de los otros críticos ha mencionado que después de ver solo 1 Oz Episodio, estará enganchado. Tienen razón, ya que e...\n",
      "  Limpia  : uno de los otros criticos ha mencionado que despues de ver solo oz episodio estara enganchado tienen razon ya que esto e...\n",
      "\n",
      "- Original: Una pequeña pequeña producción.La técnica de filmación es muy incuestionable, muy antigua, la moda de la BBC y le da una...\n",
      "  Limpia  : una pequena pequena produccion la tecnica de filmacion es muy incuestionable muy antigua la moda de la bbc y le da una s...\n",
      "\n",
      "- Original: Pensé que esta era una manera maravillosa de pasar tiempo en un fin de semana de verano demasiado caliente, sentado en e...\n",
      "  Limpia  : pense que esta era una manera maravillosa de pasar tiempo en un fin de semana de verano demasiado caliente sentado en el...\n",
      "\n",
      "- Original: Básicamente, hay una familia donde un niño pequeño (Jake) piensa que hay un zombie en su armario y sus padres están luch...\n",
      "  Limpia  : basicamente hay una familia donde un nino pequeno jake piensa que hay un zombie en su armario y sus padres estan luchand...\n",
      "\n",
      "- Original: El \"amor en el tiempo\" de Petter Mattei es una película visualmente impresionante para ver. El Sr. Mattei nos ofrece un ...\n",
      "  Limpia  : el amor en el tiempo de petter mattei es una pelicula visualmente impresionante para ver el sr mattei nos ofrece un retr...\n",
      "\n",
      "Filas totales: 3,001 | Vacías tras limpieza: 0\n"
     ]
    }
   ],
   "source": [
    "# Normalización del texto\n",
    "def limpiar_texto(texto: str) -> str:\n",
    "    # 1) a minúsculas\n",
    "    s = str(texto).lower().strip()\n",
    "    # 2) quitar tildes/diacríticos\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    # 3) remover URLs, emails, @usuarios, #hashtags\n",
    "    s = re.sub(r'https?://\\S+|www\\.\\S+', ' ', s)\n",
    "    s = re.sub(r'\\S+@\\S+\\.\\S+', ' ', s)\n",
    "    s = re.sub(r'[@#]\\w+', ' ', s)\n",
    "    # 4) dejar solo letras y espacios (mantiene ñ/ü ya sin tilde -> n/u)\n",
    "    s = re.sub(r'[^a-zñü\\s]', ' ', s)\n",
    "    # 5) espacios múltiples a uno\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s.strip()\n",
    "\n",
    "# Crear columna normalizada\n",
    "df['reseña_limpia'] = df['reseña'].astype(str).apply(limpiar_texto)\n",
    "\n",
    "# Vistazo rápido\n",
    "print(\"Ejemplo (antes y después):\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"- Original: {df['reseña'].iloc[i][:120]}...\")\n",
    "    print(f\"  Limpia  : {df['reseña_limpia'].iloc[i][:120]}...\\n\")\n",
    "\n",
    "# Chequeos básicos\n",
    "n_vacias = (df['reseña_limpia'].str.len() == 0).sum()\n",
    "print(f\"Filas totales: {len(df):,} | Vacías tras limpieza: {n_vacias:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f2144",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e04a5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords base: 88 | preservadas: 22 | usadas (custom): 85\n",
      "\n",
      "Ejemplos (antes y sin stopwords):\n",
      "\n",
      "- Limpia : uno de los otros criticos ha mencionado que despues de ver solo oz episodio estara enganchado tienen razon ya que esto e...\n",
      "  SinSW : otros criticos ha mencionado despues ver solo oz episodio enganchado razon esto exactamente sucedio conmigo primera cosa...\n",
      "\n",
      "- Limpia : una pequena pequena produccion la tecnica de filmacion es muy incuestionable muy antigua la moda de la bbc y le da una s...\n",
      "  SinSW : pequena pequena produccion tecnica filmacion muy incuestionable muy antigua moda bbc da sensacion realismo reconfortante...\n",
      "\n",
      "- Limpia : pense que esta era una manera maravillosa de pasar tiempo en un fin de semana de verano demasiado caliente sentado en el...\n",
      "  SinSW : pense manera maravillosa pasar tiempo fin semana verano demasiado caliente sentado teatro aire acondicionado observando ...\n",
      "\n",
      "- Limpia : basicamente hay una familia donde un nino pequeno jake piensa que hay un zombie en su armario y sus padres estan luchand...\n",
      "  SinSW : basicamente familia nino pequeno jake piensa zombie armario padres luchando todo tiempo pelicula mas lenta telenovela re...\n",
      "\n",
      "- Limpia : el amor en el tiempo de petter mattei es una pelicula visualmente impresionante para ver el sr mattei nos ofrece un retr...\n",
      "  SinSW : amor tiempo petter mattei pelicula visualmente impresionante ver sr mattei ofrece retrato vivido relaciones humanas peli...\n",
      "\n",
      "Vocab (muestra) antes: 44,086 | después: 44,005\n"
     ]
    }
   ],
   "source": [
    "# Stopwords PERSONALIZADAS (sentimiento)\n",
    "\n",
    "# 1) Intentar disponer de stopwords NLTK \n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "except Exception:\n",
    "    try:\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    # misma normalización: minúsculas + sin diacríticos + espacios compactados\n",
    "    s = s.lower().strip()\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s\n",
    "\n",
    "# 2) Base de stopwords \n",
    "try:\n",
    "    sw_base = set(stopwords.words(\"spanish\"))\n",
    "except Exception:\n",
    "    sw_base = set(\"\"\"\n",
    "a al algo algunas algunos ante antes como con contra cual cuales cuando de del desde donde durante e el ella ellas ellos en \n",
    "entre era erais eramos eran es esa esas ese eso esos esta estaba estaban estabais estabamos estas estan estar estara este estos \n",
    "fui fue fueron hemos hay la las le les lo los me mi mientras nada ni nos nosotras nosotros o os para pues que se ser si sin \n",
    "sobre su sus te ti tiene tienen tuvo un una uno unos y ya\n",
    "\"\"\".split())\n",
    "\n",
    "# Normaliza igual que el texto\n",
    "sw_base = {_norm(w) for w in sw_base}\n",
    "\n",
    "# 3) Palabras que **NO** se eliminan\n",
    "preservar = {\n",
    "    # Negaciones\n",
    "    \"no\",\"ni\",\"nunca\",\"jamas\",\"sin\",\"tampoco\",\n",
    "    # Contrastivos\n",
    "    \"pero\",\"aunque\",\n",
    "    # Intensificadores/atenuadores\n",
    "    \"muy\",\"bastante\",\"demasiado\",\"poco\",\"nada\",\"apenas\",\n",
    "    \"totalmente\",\"sumamente\",\"realmente\",\"tan\",\"mas\",\"menos\",\"super\",\"re\"\n",
    "}\n",
    "preservar = {_norm(w) for w in preservar}\n",
    "\n",
    "# 4) Construir la lista\n",
    "stopwords_custom = sorted([w for w in sw_base if w not in preservar])\n",
    "stopwords_custom_set = set(stopwords_custom)\n",
    "\n",
    "print(f\"Stopwords base: {len(sw_base)} | preservadas: {len(preservar)} | usadas (custom): {len(stopwords_custom)}\")\n",
    "\n",
    "# 5) Crea un texto sin stopwords\n",
    "def quitar_stopwords(texto: str):\n",
    "    # reseña_limpia tiene solo letras y espacios, por lo que dividir por espacio es suficiente\n",
    "    toks = texto.split()\n",
    "    toks = [t for t in toks if t not in stopwords_custom_set]\n",
    "    return toks\n",
    "\n",
    "df[\"tokens_sin_stop\"] = df[\"reseña_limpia\"].apply(quitar_stopwords)\n",
    "df[\"reseña_sin_stop\"] = df[\"tokens_sin_stop\"].apply(lambda ts: \" \".join(ts))\n",
    "\n",
    "# 6) Vista rápida\n",
    "print(\"\\nEjemplos (antes y sin stopwords):\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"- Limpia : {df['reseña_limpia'].iloc[i][:120]}...\")\n",
    "    print(f\"  SinSW : {df['reseña_sin_stop'].iloc[i][:120]}...\\n\")\n",
    "\n",
    "# (Opcional) pequeña métrica de reducción de vocabulario en una muestra\n",
    "muestra = df[\"reseña_limpia\"].sample(min(20000, len(df)), random_state=42)\n",
    "vocab_antes = set(\" \".join(muestra).split())\n",
    "muestra2 = df.loc[muestra.index, \"reseña_sin_stop\"]\n",
    "vocab_despues = set(\" \".join(muestra2).split())\n",
    "print(f\"Vocab (muestra) antes: {len(vocab_antes):,} | después: {len(vocab_despues):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af0e794",
   "metadata": {},
   "source": [
    "### Tokenización + Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d8ef242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     reseña_sin_stop  \\\n",
      "0  otros criticos ha mencionado despues ver solo ...   \n",
      "1  pequena pequena produccion tecnica filmacion m...   \n",
      "2  pense manera maravillosa pasar tiempo fin sema...   \n",
      "3  basicamente familia nino pequeno jake piensa z...   \n",
      "4  amor tiempo petter mattei pelicula visualmente...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [otros, criticos, ha, mencionado, despues, ver...   \n",
      "1  [pequena, pequena, produccion, tecnica, filmac...   \n",
      "2  [pense, manera, maravillosa, pasar, tiempo, fi...   \n",
      "3  [basicamente, familia, nino, pequeno, jake, pi...   \n",
      "4  [amor, tiempo, petter, mattei, pelicula, visua...   \n",
      "\n",
      "                                         tokens_stem  \n",
      "0  [otros, critic, ha, mencion, despu, ver, sol, ...  \n",
      "1  [pequen, pequen, produccion, tecnic, filmacion...  \n",
      "2  [pens, maner, maravill, pas, tiemp, fin, seman...  \n",
      "3  [basic, famili, nin, pequen, jak, piens, zombi...  \n",
      "4  [amor, tiemp, pett, mattei, pelicul, visual, i...  \n"
     ]
    }
   ],
   "source": [
    "# TOKENIZACIÓN + STEMMING \n",
    "\n",
    "# 1) Tokenizar: tu texto ya está normalizado y sin signos\n",
    "df[\"tokens\"] = df[\"reseña_sin_stop\"].str.split()\n",
    "\n",
    "# 2) Stemming en español\n",
    "try:\n",
    "    from nltk.stem.snowball import SpanishStemmer\n",
    "    _stemmer = SpanishStemmer()\n",
    "    def stem(t): return _stemmer.stem(t)\n",
    "except Exception:\n",
    "    def stem(t): return t  # si no hay stemmer, deja el token tal cual\n",
    "\n",
    "df[\"tokens_stem\"] = df[\"tokens\"].apply(lambda toks: [stem(t) for t in toks])\n",
    "df[\"reseña_stem\"] = df[\"tokens_stem\"].apply(lambda ts: \" \".join(ts))\n",
    "\n",
    "print(df[[\"reseña_sin_stop\",\"tokens\",\"tokens_stem\"]].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df0234",
   "metadata": {},
   "source": [
    "### Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88c09398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sugerencias generadas: 1058 sobre 2000 palabras raras.\n",
      "                                       reseña_limpia  \\\n",
      "0  uno de los otros criticos ha mencionado que de...   \n",
      "1  una pequena pequena produccion la tecnica de f...   \n",
      "2  pense que esta era una manera maravillosa de p...   \n",
      "3  basicamente hay una familia donde un nino pequ...   \n",
      "4  el amor en el tiempo de petter mattei es una p...   \n",
      "\n",
      "                                  reseña_limpia_corr  \n",
      "0  uno de los otros criticos ha mencionado que de...  \n",
      "1  una pequena pequena produccion la tecnica de f...  \n",
      "2  pense que esta era una manera maravillosa de p...  \n",
      "3  basicamente hay una familia donde un nino pequ...  \n",
      "4  el amor en el tiempo de peter mattei es una pe...  \n",
      "                                     reseña_sin_stop  \\\n",
      "0  otros criticos ha mencionado despues ver solo ...   \n",
      "1  pequena pequena produccion tecnica filmacion m...   \n",
      "2  pense manera maravillosa pasar tiempo fin sema...   \n",
      "3  basicamente familia nino pequeno jake piensa z...   \n",
      "4  amor tiempo petter mattei pelicula visualmente...   \n",
      "\n",
      "                                reseña_sin_stop_corr  \n",
      "0  otros criticos ha mencionado despues ver solo ...  \n",
      "1  pequena pequena produccion tecnica filmacion m...  \n",
      "2  pense manera maravillosa pasar tiempo fin sema...  \n",
      "3  basicamente familia nino pequeno jake piensa z...  \n",
      "4  amor tiempo peter mattei pelicula visualmente ...  \n"
     ]
    }
   ],
   "source": [
    "# 1) Distancia de Levenshtein (iterativa, O(m*n)) \n",
    "def levenshtein(a: str, b: str) -> int:\n",
    "    m, n = len(a), len(b)\n",
    "    if m == 0: return n\n",
    "    if n == 0: return m\n",
    "    dp = list(range(n+1))\n",
    "    for i in range(1, m+1):\n",
    "        prev, dp[0] = dp[0], i\n",
    "        for j in range(1, n+1):\n",
    "            cur = prev if a[i-1] == b[j-1] else prev + 1\n",
    "            cur = min(cur, dp[j] + 1, dp[j-1] + 1)\n",
    "            prev, dp[j] = dp[j], cur\n",
    "    return dp[-1]\n",
    "\n",
    "# 2) Vocabulario sobre el texto normalizado \n",
    "vocab = Counter(\" \".join(df[\"reseña_limpia\"]).split())\n",
    "\n",
    "RARE_MAX_FREQ   = 2   # palabras con frecuencia <=2 se consideran \"raras\"\n",
    "COMMON_MIN_FREQ = 5   # y >=5 \"comunes\" (ajusta según tamaño de corpus)\n",
    "\n",
    "rare   = [w for w,c in vocab.items() if c <= RARE_MAX_FREQ and len(w) >= 4]\n",
    "common = [w for w,c in vocab.items() if c >= COMMON_MIN_FREQ]\n",
    "\n",
    "# pequeña indexación por prefijo para acelerar búsquedas\n",
    "buckets = defaultdict(list)\n",
    "for w in common:\n",
    "    buckets[w[:2]].append(w)\n",
    "\n",
    "def mejor_vecino(word: str, max_d=2):\n",
    "    cand = buckets.get(word[:2], []) + buckets.get(word[:1], [])\n",
    "    best, best_d = None, 99\n",
    "    for c in cand:\n",
    "        if abs(len(c) - len(word)) > max_d:\n",
    "            continue\n",
    "        d = levenshtein(word, c)\n",
    "        if d < best_d:\n",
    "            best, best_d = c, d\n",
    "            if best_d == 1:\n",
    "                break\n",
    "    return best, best_d\n",
    "\n",
    "# limita el número de raras para tiempo de cómputo (sube si tu máquina puede)\n",
    "MAX_RARE = 2000\n",
    "subset_rare = rare[:MAX_RARE]\n",
    "\n",
    "sugerencias = {}\n",
    "for w in subset_rare:\n",
    "    cand, dist = mejor_vecino(w, max_d=2)\n",
    "    if cand is not None and dist <= 2:\n",
    "        sugerencias[w] = cand\n",
    "\n",
    "print(f\"Sugerencias generadas: {len(sugerencias)} sobre {len(subset_rare)} palabras raras.\")\n",
    "\n",
    "# 3) Aplicar correcciones al texto\n",
    "def aplicar_correcciones(texto: str, corr: dict):\n",
    "    toks = texto.split()\n",
    "    toks = [corr.get(t, t) for t in toks]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "# Versión corregida del normalizado y del sin stopwords\n",
    "df[\"reseña_limpia_corr\"]   = df[\"reseña_limpia\"].apply(lambda s: aplicar_correcciones(s, sugerencias))\n",
    "df[\"reseña_sin_stop_corr\"] = df[\"reseña_sin_stop\"].apply(lambda s: aplicar_correcciones(s, sugerencias))\n",
    "\n",
    "# (Opcional) stemming sobre el texto corregido sin stopwords\n",
    "df[\"tokens_corr\"]      = df[\"reseña_sin_stop_corr\"].str.split()\n",
    "df[\"tokens_stem_corr\"] = df[\"tokens_corr\"].apply(lambda ts: [stem(t) for t in ts])\n",
    "\n",
    "print(df[[\"reseña_limpia\",\"reseña_limpia_corr\"]].head(5))\n",
    "print(df[[\"reseña_sin_stop\",\"reseña_sin_stop_corr\"]].head(5))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
