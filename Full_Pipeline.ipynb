{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce25c34",
   "metadata": {},
   "source": [
    "# Proyecto 1 NLP – Clasificación supervisada\n",
    "\n",
    "**Universidad del Valle de Guatemala**  \n",
    "**Facultad de Ingeniería**  \n",
    "**Departamento de Ciencias de la Computación**  \n",
    "**Procesamiento de Lenguaje Natural**   \n",
    "\n",
    "## Integrantes: \n",
    "- Pablo Orellana\n",
    "- Diego Leiva\n",
    "- Renatto Guzmán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed535ae",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec65bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8013c",
   "metadata": {},
   "source": [
    "## 1. Preprocesamiento del Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fddc4f",
   "metadata": {},
   "source": [
    "### Cargar Corpus\n",
    "\n",
    "Corpus obtenido de Kaggle en: [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/luisdiegofv97/imdb-dataset-of-50k-movie-reviews-spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60b0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset ===\n",
      "Documentos: 50000\n",
      "Características: 5\n",
      "\n",
      "=== Información del Dataset ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   50000 non-null  int64 \n",
      " 1   review_en    50000 non-null  object\n",
      " 2   review_es    50000 non-null  object\n",
      " 3   sentiment    50000 non-null  object\n",
      " 4   sentimiento  50000 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.9+ MB\n",
      "\n",
      "=== Primeras 5 filas del Dataset ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_en</th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          review_en  \\\n",
       "0           0  One of the other reviewers has mentioned that ...   \n",
       "1           1  A wonderful little production. The filming tec...   \n",
       "2           2  I thought this was a wonderful way to spend ti...   \n",
       "3           3  Basically there's a family where a little boy ...   \n",
       "4           4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                           review_es sentiment sentimiento  \n",
       "0  Uno de los otros críticos ha mencionado que de...  positive    positivo  \n",
       "1  Una pequeña pequeña producción.La técnica de f...  positive    positivo  \n",
       "2  Pensé que esta era una manera maravillosa de p...  positive    positivo  \n",
       "3  Básicamente, hay una familia donde un niño peq...  negative    negativo  \n",
       "4  El \"amor en el tiempo\" de Petter Mattei es una...  positive    positivo  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/IMDB Dataset SPANISH.csv')\n",
    "print(f\"=== Dataset ===\")\n",
    "print(f\"Documentos: {df.shape[0]}\")\n",
    "print(f\"Características: {df.shape[1]}\\n\")\n",
    "print(\"=== Información del Dataset ===\")\n",
    "df.info()\n",
    "print(\"\\n=== Primeras 5 filas del Dataset ===\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683ebcb",
   "metadata": {},
   "source": [
    "### Procesamiento de DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cec5723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Procesado ===\n",
      "Documentos: 49599\n",
      "Características: 2\n",
      "\n",
      "\n",
      "=== Primeras 5 filas del Dataset ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentimiento\n",
       "0  Uno de los otros críticos ha mencionado que de...            1\n",
       "1  Una pequeña pequeña producción.La técnica de f...            1\n",
       "2  Pensé que esta era una manera maravillosa de p...            1\n",
       "3  Básicamente, hay una familia donde un niño peq...            0\n",
       "4  El \"amor en el tiempo\" de Petter Mattei es una...            1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar columnas en ingles o innecesarias\n",
    "df = df.drop(columns=['review_en', 'Unnamed: 0', 'sentiment'])\n",
    "\n",
    "# Renombrar columnas\n",
    "df = df.rename(columns={'review_es': 'review'})\n",
    "\n",
    "# Convertir variable objetivo a binaria\n",
    "df['sentimiento'] = df['sentimiento'].map({'positivo': 1, 'negativo': 0})\n",
    "\n",
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"=== Dataset Procesado ===\")\n",
    "print(f\"Documentos: {df.shape[0]}\")\n",
    "print(f\"Características: {df.shape[1]}\\n\")\n",
    "print(\"\\n=== Primeras 5 filas del Dataset ===\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c99ad7",
   "metadata": {},
   "source": [
    "### Normalización de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e435140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Función para limpiar y normalizar texto en español.\n",
    "    Parámetros:\n",
    "        texto (str): Texto a limpiar.\n",
    "    Retorna:\n",
    "        str: Texto limpio y normalizado.\n",
    "    \"\"\"\n",
    "    # 1) a minúsculas\n",
    "    s = str(texto).lower().strip()\n",
    "    # 2) quitar tildes/diacríticos\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    # 3) remover URLs, emails, @usuarios, #hashtags\n",
    "    s = re.sub(r'https?://\\S+|www\\.\\S+', ' ', s)\n",
    "    s = re.sub(r'\\S+@\\S+\\.\\S+', ' ', s)\n",
    "    s = re.sub(r'[@#]\\w+', ' ', s)\n",
    "    # 4) quitar puntuación y símbolos\n",
    "    s = re.sub(r'[^\\w\\s]', ' ', s, flags=re.UNICODE)  # elimina ¡¿, comas, puntos, comillas, etc.\n",
    "    s = re.sub(r'_', ' ', s)\n",
    "    # 5) espacios múltiples a uno\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    # 6) eliminar numeros\n",
    "    s = re.sub(r'\\d+', ' ', s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce6dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo (antes y después):\n",
      "\n",
      "- Original: Uno de los otros críticos ha mencionado que despué...\n",
      "- Limpia  : uno de los otros criticos ha mencionado que despue...\n",
      "\n",
      "- Original: Una pequeña pequeña producción.La técnica de filma...\n",
      "- Limpia  : una pequena pequena produccion la tecnica de filma...\n",
      "\n",
      "- Original: Pensé que esta era una manera maravillosa de pasar...\n",
      "- Limpia  : pense que esta era una manera maravillosa de pasar...\n",
      "\n",
      "- Original: Básicamente, hay una familia donde un niño pequeño...\n",
      "- Limpia  : basicamente hay una familia donde un nino pequeno ...\n",
      "\n",
      "- Original: El \"amor en el tiempo\" de Petter Mattei es una pel...\n",
      "- Limpia  : el amor en el tiempo de petter mattei es una pelic...\n",
      "\n",
      "Número de filas con texto vacío después de la limpieza: 0\n",
      "Filas restantes después de eliminar textos vacíos: 49599\n"
     ]
    }
   ],
   "source": [
    "# Crear columna normalizada\n",
    "df[\"review_norm\"] = df[\"review\"].apply(limpiar_texto)\n",
    "\n",
    "# Mostrar ejemplos de limpieza\n",
    "print(\"Ejemplo (antes y después):\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"- Original: {df['review'].iloc[i][:50]}...\")\n",
    "    print(f\"- Limpia  : {df['review_norm'].iloc[i][:50]}...\\n\")\n",
    "\n",
    "# Verificar si hay vacios después de la limpieza\n",
    "vacios = df['review_norm'].str.strip().eq('')\n",
    "print(f\"Número de filas con texto vacío después de la limpieza: {vacios.sum()}\")\n",
    "# Eliminar filas con texto vacío\n",
    "df = df[~vacios]\n",
    "print(f\"Filas restantes después de eliminar textos vacíos: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ef349",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "Se amplian las stopwords de NTLK con el conjunto de stopwords de [alir3z4 Stop Words](https://alir3z4.github.io/stop-words/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728f4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza una cadena de texto, convirtiéndola a minúsculas, eliminando tildes y espacios en blanco.\n",
    "    Parámetros:\n",
    "        s (str): Cadena de texto a normalizar.\n",
    "    Retorna:\n",
    "        str: Cadena de texto normalizada.\n",
    "    \"\"\"\n",
    "    s = s.lower().strip()\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def norm_set(words):\n",
    "    \"\"\"\n",
    "    Normaliza un conjunto de palabras.\n",
    "    Parámetros:\n",
    "        words (iterable): Conjunto de palabras a normalizar.\n",
    "    Retorna:\n",
    "        set: Conjunto de palabras normalizadas.\n",
    "    \"\"\"\n",
    "    return {normalize(w) for w in words if w.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b0a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords finales: 564\n",
      "\n",
      "Ejemplos (antes y sin stopwords):\n",
      "\n",
      "- Reseña        : uno de los otros criticos ha mencionado que despue...\n",
      "- Sin Stopwords : criticos mencionado oz episodio enganchado razon e...\n",
      "\n",
      "- Reseña        : una pequena pequena produccion la tecnica de filma...\n",
      "- Sin Stopwords : pequena pequena produccion tecnica filmacion muy i...\n",
      "\n",
      "- Reseña        : pense que esta era una manera maravillosa de pasar...\n",
      "- Sin Stopwords : pense maravillosa pasar semana verano demasiado ca...\n",
      "\n",
      "- Reseña        : basicamente hay una familia donde un nino pequeno ...\n",
      "- Sin Stopwords : basicamente familia nino pequeno jake piensa zombi...\n",
      "\n",
      "- Reseña        : el amor en el tiempo de petter mattei es una pelic...\n",
      "- Sin Stopwords : amor petter mattei pelicula visualmente impresiona...\n",
      "\n",
      "Número de filas con texto vacío después de remover stopwords: 0\n",
      "Filas restantes después de eliminar textos vacíos: 49599\n"
     ]
    }
   ],
   "source": [
    "# Descargar stopwords de NLTK si no se han descargado\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# 1) base y extras\n",
    "sw_base = set(stopwords.words('spanish'))\n",
    "with open(\"Data/spanish_stopwords.txt\", encoding=\"utf-8\") as f:\n",
    "    sw_extra = {line.strip() for line in f if line.strip()}\n",
    "\n",
    "# 2) protegidas\n",
    "negaciones = {\n",
    "    \"no\",\"nunca\",\"jamas\",\"ni\",\"sin\",\"tampoco\",\"ningun\",\n",
    "    \"ninguna\",\"ninguno\",\"ningunas\",\"ningunos\",\"nadie\",\"nada\"\n",
    "    }\n",
    "contrastivos = {\n",
    "    \"pero\",\"aunque\",\"sin\",\"embargo\",\"sinembargo\",\"no\",\n",
    "    \"obstante\",\"sino\",\"excepto\",\"salvo\",\"aunquesi\"\n",
    "    }\n",
    "intensif = {\"muy\",\"tan\",\"tanto\",\"tantos\",\"tantas\",\n",
    "            \"demasiado\",\"demasiada\",\"demasiados\",\n",
    "            \"demasiadas\",\"super\",\"re\",\"hiper\",\"bastante\",\n",
    "            \"apenas\",\"poco\",\"poca\",\"pocos\",\"pocas\",\"casi\",\n",
    "            \"algo\",\"sumamente\"\n",
    "            }\n",
    "\n",
    "protegidas = negaciones | contrastivos | intensif\n",
    "\n",
    "# 3) normalizar todo\n",
    "sw_total_norm = norm_set(sw_base | sw_extra) - norm_set(protegidas)\n",
    "print(\"Stopwords finales:\", len(sw_total_norm))\n",
    "\n",
    "# 4) regex con bordes de palabra\n",
    "pattern = re.compile(r'\\b(?:' + '|'.join(sorted(map(re.escape, sw_total_norm), key=len, reverse=True)) + r')\\b')\n",
    "\n",
    "# 5) aplicar a la columna ya normalizada\n",
    "df[\"review_sin_sw\"] = (\n",
    "    df[\"review_norm\"]\n",
    "      .str.replace(pattern, \" \", regex=True)\n",
    "      .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "      .str.strip()\n",
    ")\n",
    "\n",
    "# Chequeo rápido\n",
    "print(\"\\nEjemplos (antes y sin stopwords):\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"- Reseña        : {df['review_norm'].iloc[i][:50]}...\")\n",
    "    print(f\"- Sin Stopwords : {df['review_sin_sw'].iloc[i][:50]}...\\n\")\n",
    "\n",
    "# Verificar si hay vacios después de remover stopwords\n",
    "vacios_sw = df['review_sin_sw'].str.strip().eq('')\n",
    "print(f\"Número de filas con texto vacío después de remover stopwords: {vacios_sw.sum()}\")\n",
    "# Eliminar filas con texto vacío\n",
    "df = df[~vacios_sw]\n",
    "print(f\"Filas restantes después de eliminar textos vacíos: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc4e3f",
   "metadata": {},
   "source": [
    "### Tokenización y Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d9dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>review_norm</th>\n",
       "      <th>review_sin_sw</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>1</td>\n",
       "      <td>uno de los otros criticos ha mencionado que de...</td>\n",
       "      <td>criticos mencionado oz episodio enganchado raz...</td>\n",
       "      <td>[criticos, mencionado, oz, episodio, enganchad...</td>\n",
       "      <td>[critic, mencion, oz, episodi, enganch, razon,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>1</td>\n",
       "      <td>una pequena pequena produccion la tecnica de f...</td>\n",
       "      <td>pequena pequena produccion tecnica filmacion m...</td>\n",
       "      <td>[pequena, pequena, produccion, tecnica, filmac...</td>\n",
       "      <td>[pequen, pequen, produccion, tecnic, filmacion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>1</td>\n",
       "      <td>pense que esta era una manera maravillosa de p...</td>\n",
       "      <td>pense maravillosa pasar semana verano demasiad...</td>\n",
       "      <td>[pense, maravillosa, pasar, semana, verano, de...</td>\n",
       "      <td>[pens, maravill, pas, seman, veran, demasi, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>0</td>\n",
       "      <td>basicamente hay una familia donde un nino pequ...</td>\n",
       "      <td>basicamente familia nino pequeno jake piensa z...</td>\n",
       "      <td>[basicamente, familia, nino, pequeno, jake, pi...</td>\n",
       "      <td>[basic, famili, nin, pequen, jak, piens, zombi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>1</td>\n",
       "      <td>el amor en el tiempo de petter mattei es una p...</td>\n",
       "      <td>amor petter mattei pelicula visualmente impres...</td>\n",
       "      <td>[amor, petter, mattei, pelicula, visualmente, ...</td>\n",
       "      <td>[amor, pett, mattei, pelicul, visual, impresio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentimiento  \\\n",
       "0  Uno de los otros críticos ha mencionado que de...            1   \n",
       "1  Una pequeña pequeña producción.La técnica de f...            1   \n",
       "2  Pensé que esta era una manera maravillosa de p...            1   \n",
       "3  Básicamente, hay una familia donde un niño peq...            0   \n",
       "4  El \"amor en el tiempo\" de Petter Mattei es una...            1   \n",
       "\n",
       "                                         review_norm  \\\n",
       "0  uno de los otros criticos ha mencionado que de...   \n",
       "1  una pequena pequena produccion la tecnica de f...   \n",
       "2  pense que esta era una manera maravillosa de p...   \n",
       "3  basicamente hay una familia donde un nino pequ...   \n",
       "4  el amor en el tiempo de petter mattei es una p...   \n",
       "\n",
       "                                       review_sin_sw  \\\n",
       "0  criticos mencionado oz episodio enganchado raz...   \n",
       "1  pequena pequena produccion tecnica filmacion m...   \n",
       "2  pense maravillosa pasar semana verano demasiad...   \n",
       "3  basicamente familia nino pequeno jake piensa z...   \n",
       "4  amor petter mattei pelicula visualmente impres...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [criticos, mencionado, oz, episodio, enganchad...   \n",
       "1  [pequena, pequena, produccion, tecnica, filmac...   \n",
       "2  [pense, maravillosa, pasar, semana, verano, de...   \n",
       "3  [basicamente, familia, nino, pequeno, jake, pi...   \n",
       "4  [amor, petter, mattei, pelicula, visualmente, ...   \n",
       "\n",
       "                                         tokens_stem  \n",
       "0  [critic, mencion, oz, episodi, enganch, razon,...  \n",
       "1  [pequen, pequen, produccion, tecnic, filmacion...  \n",
       "2  [pens, maravill, pas, seman, veran, demasi, ca...  \n",
       "3  [basic, famili, nin, pequen, jak, piens, zombi...  \n",
       "4  [amor, pett, mattei, pelicul, visual, impresio...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar recursos de NLTK si no se han descargado\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Inicializar el stemmer en español\n",
    "stemmer = SpanishStemmer()\n",
    "\n",
    "# Aplicar stemming a la columna sin stopwords\n",
    "# tokens crudos (sin stopwords)\n",
    "df[\"tokens\"] = df[\"review_sin_sw\"].apply(lambda x: word_tokenize(x, language=\"spanish\"))\n",
    "\n",
    "# tokens stem (lista)\n",
    "df[\"tokens_stem\"] = df[\"tokens\"].apply(lambda xs: [stemmer.stem(t) for t in xs])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da390013",
   "metadata": {},
   "source": [
    "### Levenshtein\n",
    "No se aplica a todo el dataset debido a que:\n",
    "- El corpus tiene ~50 000 reseñas → millones de palabras únicas.\n",
    "- Comparar cada palabra con todas las demás sería $(O(n^2))$, ineficiente y sin valor práctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3037c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(a: str, b: str) -> int:\n",
    "    \"\"\"\n",
    "    Distancia de edición mínima entre a y b.\n",
    "    \n",
    "    Parámetros:\n",
    "        a (str): Primera cadena.\n",
    "        b (str): Segunda cadena.\n",
    "    Retorna:\n",
    "        int: Distancia de edición mínima.\n",
    "        \"\"\"\n",
    "    if a == b:\n",
    "        return 0\n",
    "    if not a:\n",
    "        return len(b)\n",
    "    if not b:\n",
    "        return len(a)\n",
    "    dp = np.zeros((len(a)+1, len(b)+1), dtype=int)\n",
    "    dp[0, :] = np.arange(len(b)+1)\n",
    "    dp[:, 0] = np.arange(len(a)+1)\n",
    "    for i in range(1, len(a)+1):\n",
    "        for j in range(1, len(b)+1):\n",
    "            cost = 0 if a[i-1] == b[j-1] else 1\n",
    "            dp[i, j] = min(dp[i-1, j]+1, dp[i, j-1]+1, dp[i-1, j-1]+cost)\n",
    "    return dp[len(a), len(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e233a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario total: 169469 palabras\n",
      "Palabra: exelente → Sugerencia más cercana: entiende\n",
      "\n",
      "Ejemplos de correcciones detectadas:\n",
      "negociable → negociables\n",
      "pilotada → pilotado\n",
      "sidewalks → sidewalk\n",
      "chateas → chatear\n",
      "isenti → senti\n",
      "gaseados → gaseado\n",
      "brosnon → brosnan\n",
      "carano → parano\n",
      "infidel → infiel\n",
      "bragging → dragging\n"
     ]
    }
   ],
   "source": [
    "# Construcción del vocabulario\n",
    "# Tomamos los tokens sin stem para detectar errores reales\n",
    "vocab_counts = Counter(t for toks in df[\"tokens\"] for t in toks)\n",
    "print(f\"Vocabulario total: {len(vocab_counts)} palabras\")\n",
    "\n",
    "# Palabras frecuentes (consideradas válidas)\n",
    "freq_words = {w for w, c in vocab_counts.items() if c >= 5}\n",
    "\n",
    "# Ejemplo de corrección\n",
    "palabra = \"exelente\"\n",
    "distancias = {w: levenshtein(palabra, w) for w in list(freq_words)[:2000]}  # comparar con un subconjunto\n",
    "sugerencia = min(distancias, key=distancias.get)\n",
    "print(f\"Palabra: {palabra} → Sugerencia más cercana: {sugerencia}\")\n",
    "\n",
    "# Opcional: aplicar a todo el vocabulario raro (<3 apariciones)\n",
    "rare = {w for w, c in vocab_counts.items() if c < 3}\n",
    "correcciones = {}\n",
    "for w in list(rare)[:20]:\n",
    "    candidatos = {v: levenshtein(w, v) for v in freq_words if abs(len(v)-len(w)) <= 2}\n",
    "    if candidatos:\n",
    "        best = min(candidatos, key=candidatos.get)\n",
    "        if candidatos[best] <= 1:\n",
    "            correcciones[w] = best\n",
    "\n",
    "print(\"\\nEjemplos de correcciones detectadas:\")\n",
    "for k, v in list(correcciones.items())[:10]:\n",
    "    print(f\"{k} → {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
